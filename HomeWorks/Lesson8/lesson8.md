 
1. Создал кластер, по:
   ```shell
   pg_createcluster --start --start-conf=manual 14 main
   ```
   Опция `--start-conf=manual` нужна осознанно, ниже будет скриптоваться процесс перезапуска кластера, от не привилегированного пользователя ОС-и.
   Иначе - пропишется в системный ферймворк обслуживания сервисов, и будет требовать работать ч/з фреймворк.
   ![8_1](/HomeWorks/Lesson8/8_1.png)
2. Применил параметры из файла указанного в ДЗ:
   ![8_2](/HomeWorks/Lesson8/8_2.png)
   Кстати, только тут сообразил что в пг - настройки задаваемые для кластера: действуют, одинаковые, во всех субд, созданных в кластере.
   Что может быть не удобно, в oracle, в мультитенант-архитектуре, сделано более продвинуто: плаггабле-базы, в контейнерной бд могут и имеют свои собственные настройки, своё ундо, свои темп-ы, свои настройки оптимизатора, pga-области, свои настройки служебных процессов.
   Дополнительно выставил, в конфиге кластера - `log_min_messages = debug1` ([дока](https://www.postgresql.org/docs/current/runtime-config-logging.html)): удобно, в логе кластера, наблюдать за сессиями запуска автовакуума:
   ![8_3](/HomeWorks/Lesson8/8_3.png)
3. Начиная с пункта ДЗ: `pgbench -i postgres` начал выполнять ДЗ с отклонениями от буквы ДЗ.
   По команде `pgbench -i postgres` - создаётся не очень подходящая табличная модель, для ловли каких то заметных эффектов, связанных с удачной/не удачной настройкой процесса вакуумировия.
   Таблиц - мало, таблицы - маленькие и таблицы очень разные по размеру: одна таблица - на порядки больше чем всё остальное.
   ![8_4](/HomeWorks/Lesson8/8_4.png)
   Учитывая что автовакуум выделяет на обработку таблицы - один процесс, получается что, по факту, речь тут будет идти только о обработке таблицы `pgbench_accounts`.
   Обработка остального - пренебрежимо мала, по затратам.
   Сканирования этого набора таблиц, даже если там будет большой процент мёртвых туплов, при таких размерах табличных сегментов данных - будет не заметен, скорее всего - прокешируется либо в шаред-буферах пг и/или в файловом кеше ОС-и.
   И тут надо будет очень интенсивно читать эти таблицы, чтобы заметить какую то разницу, которая возникает при деградировании качества чтения данных из этих структур
   В общем сделал так - `pgbench -i -s 20 -n --foreign-keys --fillfactor=50 bmdb`:
   ![8_5](/HomeWorks/Lesson8/8_5.png)
   Т.е., с учётом кол-ва памяти в вм (4G) и конфигурации пг, под файловый кэш ОС-и - остаётся немного, относительно вот этих размеров.
   Т.е. вот эти таблицы: точно в память не впишутся, полностью.
   Т.е. субд, обрабатывая sql-команды, подразумевающие фулл-скан таблицы (а только тогда эффекты от наличия какого то процента мёртвых туплов начинают негативить) - будет гонять на диск, за данными и вот тут появление и рост процента мёртвых туплов - должен значительно сильнее вызывать деградацию в латеси по доступу к данынми.
   Второй момент - заказал создание внешних ключей.
   Оно их, обратил внимание - создаёт без индексов, на столбец, являющийся внешним ключём, например:
   ![8_6](/HomeWorks/Lesson8/8_6.png)
   Вообще говоря: fk без индекса, это, конечно есть ересь и вредительство. 
   Но в данном случае это даже к лучшему - удаления строк в мастер-таблице: будут приводить либо к пробивке null-ов, в соотв-х строках дочерней таблицы, либо к удалению этих строк - а чтобы их, без индекса, найти - фуллскан.
   Вставка новой строки, изменение fk-поля, в дочерней таблице - базе надо будет бегать по мастер-таблице, по домену значений столбца, на который смотрит fk-контрейнт, с дочерней таблицы.
   Тут, конечно, будет скан индексной стр-ры, но всё таки: чуть больше чтений и индексы, насколько я понимаю, обязаны создавать и вести какие то индексные элементы смотрящие на мёртвые туплы (мало ли какая долгая транзакция есть и работает и захочет доступ к строкам, по заиндексированному столбцу, которые вчера были удалены) и вставлять новые индексные элементы для обновлённых/вновь созданных строк.
   В общем индексы должны, от транзакций фрагментироваться и накапливать версии индексных элементов ещё бодрее, чем таблицы копят версии строк, от транзакций.
   Т.е. с форенкеями, опять же, эффекты, от версионирования транзакциями строк, негативно влияющие на пропускную способность субд по транзакциям/ед. времени - долджны усиливаться.
   
   Так же: не захотел создавать тестовые таблицы в postgres-субд, создал отдельную базу: `bmdb`
   postgres-субд использовал как базу под метаданные о тестах, для чего создал, в ней, вспомогательные таблицы, секвенцию, для выполнения тестов:
   ```sql
   psql -c "create sequence public.test_seq increment by 1 start with 1 cache 20;" -U "$METADATADBUSER" "$METADATADB"
   psql -c "create table public.tests_data(test_num int, interval_start int, num_transactions int, measure_num int);" -U "$METADATADBUSER" "$METADATADB"
   psql -c "create table public.tests_metric(test_num int, length float, variance float, metric float);" -U "$METADATADBUSER" "$METADATADB"
   psql -c "create table public.tests_parameters as select 1 as testnum, name, setting from pg_settings where name in ('autovacuum_vacuum_threshold','autovacuum_vacuum_scale_factor','autovacuum_naptime','autovacuum_max_workers','autovacuum_analyze_threshold', 'autovacuum_analyze_scale_factor' );" -U "$METADATADBUSER" "$METADATADB"
   ```
4. Вот эта часть задач в ДЗ заставила задуматься:
   ```
   запустить pgbench -c8 -P 60 -T 3600 -U postgres postgres
   дать отработать до конца
   зафиксировать среднее значение tps в последней ⅙ части работы
   а дальше настроить autovacuum максимально эффективно
   так чтобы получить максимально ровное значение tps на горизонте часа
   ```
   Ну. Понятно что автовакуум, своей работой будет мешать доступу к данным в структурах данных, пока он работает.
   Т.е.: уменьшать пропускную способность субд по tps-ам (`transactions per second`)
   С другой стороны, когда и если вакуумирование структур данных - выполнено, стоимость фуллскана структуры: уменьшается и tps-метрика - увеличивается.
   Отсюда возникает "дребезг", в динамике значений tps-метрики: она начинает колебаться, вокруг какого то среднего, т.е.: есть дисперсия значений tps-метрики.
   Т.е. `максимально ровное` значение - это такая конфигурация, при работе сервиса автовакуумирования, при которой автовакуумирование: выполняется и дисперсия tps-метрики: минимальная.
   С другой стороны, если например вакуумирование - ну пусть оно работает и пусть даже дисперсия tps-метрики - минимальная, но саму tps-метрику - задавило в область нуля: это тоже должно быть не приемлемо.
   Т.е., первый вывод - метрика качества подбора конфигуарции работы автовакуума должна пониматься так: 
   
   Качество подбора конфигурации автовакуума - тем выше, чем больший tps мы получаем от субд и минимальную дисперсию tps, при выполнении бенчмарка и срабатывании автовакуума, во время бенчмарка.
   
   Математически, это выглядит как точка, в коррдинатах: по оси Y - tps, по оси X - дисперсия tps.
   И нас интересуют точки, в этом 2-мерном пространстве, с большей длинной вектора и с углом вектора, ближе к 90-градусам.
   Это можно и нужно свести к скалярной метрике: можно просто домножать длину вектора на синус угла.
   Тогда, тесты которые покажут пусть большой tps, но и большую дисперсию tps-а - это будет вектор "более прижатый" к оси Х.
   За это - мы штрафуем длинну этого вектора, тем сильнее, чем меньше угол, между вектором и осью Х.
   И размер штрафа - уменьшается, с увеличением угла.
   `sin(0)=0, sin(90)=1`
   Итого, с метрикой получается так: средняя tps, полученная в тесте, и штраф на эту среднюю tps, прямо пропорциональный величине дисперсии tps-а, вокруг этого среднего.
   Картинка, призванная пояснить эту концепцию. 
   ![8_7](/HomeWorks/Lesson8/8_7.png)
   
   Пусть, в двух тестах: `T1` и `T2`, были получены одинаковые средние tps.
   Но с разными дисперсиями, в `T2` - дисперсия tps значений, вокруг среднего, больше.
   Оценка тестов, по формуле `length(T)*sin(a)`, где `a` - угол наклона вектора, относительно оси X, покажет что тест `T1` - это тест с лучшим качеством работы, чем `T2`
   Если ещё задуматься, то, в математическом смысле, получается оптимизационная задача.
   Если обозначить набор конфигурационных пар-ров автовакуума, как `X1,X2,...Xn`, (а мы - только их варьировать и собираемся, при прочих равных), то
   надо найти экстремум (максимум) ф-ции `F(X1,X2,...Xn)=length(T)*sin(a)` варьируя конкретные значения компонент входного вектора параметров `X1,X2,...Xn`
   То что называется аргмакс.
   Это классическая оптимизационная задача.
   
   Дальше: как именно подбирать значения параметров - сказано не было, во время занятия. 
   Также не говорится об этом - в [доке](https://www.postgresql.org/docs/14/runtime-config-autovacuum.html). 
   Также не говорится об этом в [статьях в интернете](https://habr.com/ru/company/postgrespro/blog/452762/).
   Поясняется смысл параметров, но не более того.
   
   Тогда вариантов два.
   Первый вариант: то что называется "перебор по решётке", или, другое называние - "метод коррдинатного спуска".
   Смысл в том что, при фиксированных значениях `n-1` компонент входного вектора параметров, варьируем, в допустимом диапазоне значений и с каким то шагом какую то одну компоненту вектора параметров.
   И выбираем то значение этой компоненты, при котором `F(X1,X2,...Xn)` - оказалось минимальной, и далее, для этой компонеты, используем только это, выбранное значение.
   И таким же образом поступаем для выбора значений для остальных `n-1` компонент входного вектора параметров.
   Ну, плюсы варианта - просто. Минусы - очень долго, у нас, по требованию ДЗ каждый тест (т.е., в математических терминах - получение значения ф-ции `F`) - это час времени.
   
   Второй вариант: какой то оптимизационный алгоритм, который позволит найти экстремум - значительно быстрее метода координатного спуска, за меньшее кол-во вычислений целевой функции (т.е.: за меньшее кол-во тестов).
   
   Ну. Я взял генетический оптимизационный алгорим.
   Потому что другие методы: градиентный спуск, Ньютоновские методы - вообще говоря их применимость надо доказывать.
   Т.е. они требуют исследования целевой ф-ции: что она определена, что она непрерывна, что она дифференциируема, имеет счётное кол-во экстремумов и имеет глобальный один экстремум.
   Стохастические оптимизационные алгоримы - сильно более лояльны к требованиям к целевой ф-ции.
   Достаточно чтобы целевая ф-ция была вычисляема, для данного набора её входных параметров.
5. С этих пропозиций, для технической реализации, прокодировал шелл-библиотеку `library` (в аттаче: [files.tar](/HomeWorks/Lesson8/files.tar)), с ф-циями, которыми обеспечивается выполнение теста и набор шелл-скриптов, которыми реализуется выполнение ф-ций из этой библиотеки, как операций, необходимых для выполнения теста.
   ```shell
   postgres@postgresql1:~/lesson8$ ls -lthr
   total 48K
   -rwxrw-r-- 1 postgres postgres   75 Jul 30 10:30 set_parameters.sh
   -rwxrw-r-- 1 postgres postgres   65 Jul 30 10:42 get_test_id.sh
   -rwxrw-r-- 1 postgres postgres   69 Jul 30 11:24 runtest.sh
   -rwxrw-r-- 1 postgres postgres   77 Jul 30 11:33 getmetric.sh
   -rw-rw-r-- 1 postgres postgres  20K Jul 30 14:22 files.tar
   -rw-rw-r-- 1 postgres postgres 8.2K Jul 30 17:39 library
   ```
   Т.е.: выполнение теста это такая пос-ть:
   1. Получаем id-шник теста: `get_test_id.sh`
   2. Выставляется какое то конкретное значение конф-х параметров автовакуума, выполняеся рестарт кластера.
      Этим занимается `set_parameters.sh`
   3. Выполняется тест, это вызов `runtest.sh` с передачей скрипту id-шника данного теста.
      Про себя этот скрипт, выполняет такие действия, покажу код тут, благо он короткий:
      ```shell
      runtest(){
      local v_testnum="$1"
      local v_pgb_options="--client=8 --time=${TESTDURATION} --username=${DBUSER} --log --log-prefix=${PGBENCH_DIR}/temp --aggregate-interval=${INTERVAL}"
      local v_cmd="" v_rc="" v_filename=""
      
      if [[ ! "$v_testnum" =~ [0-9]+ ]]; then
         output "Uncorrect value provided as testnum: ${v_testnum}"
         return 1
      fi
      
      if [[ "$v_testnum" =~ [0-9]+ ]]; then
         $PSQL -c "insert into public.tests_parameters select ${v_testnum} as testnum, name, setting from pg_settings where name in ('autovacuum_vacuum_threshold','autovacuum_vacuum_scale_factor','autovacuum_naptime','autovacuum_max_workers','autovacuum_analyze_threshold', 'autovacuum_analyze_scale_factor' );" -U "$METADATADB" "$METADATADBUSER"
      
         find ${PGBENCH_DIR} -type f -name 'temp*' -delete
         v_cmd="${PGBENCH} ${v_pgb_options} \"$DBNAME\""
         output "doing: ${v_cmd}"
         eval "$v_cmd"
         v_rc="$?"
         #echo "$v_rc"
         if [ "$v_rc" -eq "0" ]; then
            v_filename=$( find ${PGBENCH_DIR} -type f -name 'temp*' )
            #echo "$v_filename"
            cat "$v_filename" | awk -v tn="$v_testnum" '{printf "%d,%d,%d,%d\n", tn, $1, $2, NR;}' > /tmp/temp.txt
            $PSQL -c "copy public.tests_data from '/tmp/temp.txt' with (format csv);" -U "$METADATADB" "$METADATADBUSER"
         fi
         return "$v_rc"
      else
         output "Can not obtain nextvalue from id-sequence"
         return 1
      fi
      }
      ```
      Баш-переменные такие:
      ```shell
      export DBNAME="bmdb"
      export DBUSER="postgres"
      export PSQL="/usr/bin/psql"
      export PGBENCH="/usr/bin/pgbench"
      export VERBOSE="1"
      export LOGFILE="/tmp/logfile.txt"
      export PGBENCH_DIR="$HOME/pgbench_dir"; [ ! -d "$PGBENCH_DIR" ] && mkdir -p "$PGBENCH_DIR"
      export METADATADB="postgres"
      export METADATADBUSER="postgres"
      export TESTDURATION="900"
      export INTERVAL="60"
      export SKIP_ITERATION=5
      ```
      Т.е. скрипт: сохранит выхлоп от работы `pgbench` утилиты в таблицу `public.tests_data`, в postgres-бд (`METADATADB`: это postgres-бд)
      Потом можно эти данные анализовать, находить метрику теста.
      Самой утилите `pgbench` сказано периодически (кажду минуту) подбивать и выводить в лог-файл данные tps, какой он был за эту минуту.
      Так же: сохраняется набор действующих значений, в данном тесте, параметров работы автовакуума, в отдельную служебную таблицу `public.tests_parameters`, вместе с номером теста.
   4. Делается анализ данных теста, находится и сохраняется, в таблицу `public.tests_metric` метрика и id-шник и некоторые ещё атрибуты данного теста.
      Технически это вызов скрипта `getmetric.sh` с передачей ему, аргументом, id-шника данного теста.
6. Понаблюдав за выполнениями теста, сделал ещё одно отступление от требований ДЗ: сократил продолжительность теста с 1 часа, до 15-ти минут.
   И, в коде `getmetric.sh` скипаю первые 5-ть замеров tps-метрики - они, действительно, какие то не типовые получаются.
   Надо полагать что связано с тем что, в зависимости от настроек, автовакуум может не сразу, от начала теста, начать работать.
7. Выбрал для варьирования такой набор параметров автовакуума:
   ```
   autovacuum_analyze_scale_factor		[0.01, 0.9], fl
   autovacuum_analyze_threshold		[50, 5000], int
   autovacuum_max_workers				[1,5], int
   autovacuum_naptime					[1,180], int
   autovacuum_vacuum_scale_factor		[0.01, 0.9], float
   autovacuum_vacuum_threshold			[50, 5000], int
   ```
8. Для оркестровки-автоматизации выполнения тестов использовался [cran-r](https://cran.r-project.org/)
   Этот язык программирования - отлично умеет в скрипты, отлично интегрируется с башем. 
   Код работы в `R`:
   ```shell
   pSize = 4
   elitism_value=1
   pmutation_coef=0.8
   pcrossover_coef=0.1
   iterations=20

   gam=GA::ga(type="real-valued", fitness=fr,
   lower=c(0, 0, 0, 0, 0, 0), upper=c(100, 100, 100, 100, 100, 100),
   popSize=pSize,
   pcrossover = pcrossover_coef,
   pmutation = pmutation_coef,
   maxiter=iterations,
   run=3,
   keepBest=T)
   cat( "GA-session is done" , file=v_logfile, sep="\n", append=T)
   gam@solution
   ```
9. Результаты:
   ![8_8](/HomeWorks/Lesson8/8_8.png)
   Ну. Очевидно что победитель - тест с номером `1101`; И tps-большое, и дисперсия tps-а: меньше всех.
   Кстати: хорошо видно как на метрику теста влияет большее, или меньшее значение дисперсии - пусть даже tps: большое, но если дисперсия - тоже большая, метрика теста занижается.
   В виде графика:
   ![8_9](/HomeWorks/Lesson8/8_9.png)
   
   Ну. Да, действительно, генетика, перебирая популяции и отсевая в следующую популяцию экземпляры с хорошими генами (те которые дают большее начение функции отбора) - очень быстро (относительно, например, метода координатного спуска) нашла такой то набор хромосом (значения входного вектора `X1,X2,...,Xn`, для целевой ф-ции, она же - функция отбора в генетическом алг-ме) который показывает значительно лучшую приспособленность, для поставленных условий отбора.
   Ну, в наших терминах - это тесты, которые показывают лучшую метрику.
   Посмотрим на значения tps-ов, в лучшем и худшем тестах:
   ![8_10](/HomeWorks/Lesson8/8_10.png)
   `pgbranch`, по опции `--aggregate-interval` - просто суммирует, кол-во транзакций, за заданный интервал времени (у меня - минута) внутритеста.
   Поэтому надо эти данные (значение в столбце `num_transactions`) пересчитывать - делить на кол-во секунд в интервале.
   В виде графика:
   ![8_11](/HomeWorks/Lesson8/8_11.png)
   
   Первые слева 5-ть значений, по размаху абсолютных величинам, несколько забивают остальную динамику (я потому их и пропускаю, при подсчёте метрики теста)
   Но, если смотреть на динамики кривых начиная с 6-го, слева и далее замеров - можно усмотреть что динамика для `1241` теста - "гуляет" сильнее, разброс значений, вокруг среднего: больше.
   Значения параметров, в тестах:
   ```sql
   [local]:5432 #postgres@postgres > select * from tests_parameters where testnum=1241 order by name asc;
    testnum |              name               | setting
   ---------+---------------------------------+----------
       1241 | autovacuum_analyze_scale_factor | 0.110786
       1241 | autovacuum_analyze_threshold    | 4741
       1241 | autovacuum_max_workers          | 1
       1241 | autovacuum_naptime              | 36
       1241 | autovacuum_vacuum_scale_factor  | 0.510957
       1241 | autovacuum_vacuum_threshold     | 3806
   (6 rows)
   
   [local]:5432 #postgres@postgres > select * from tests_parameters where testnum=1101 order by name asc;
    testnum |              name               |  setting
   ---------+---------------------------------+-----------
       1101 | autovacuum_analyze_scale_factor | 0.110786
       1101 | autovacuum_analyze_threshold    | 4741
       1101 | autovacuum_max_workers          | 1
       1101 | autovacuum_naptime              | 136
       1101 | autovacuum_vacuum_scale_factor  | 0.0821061
       1101 | autovacuum_vacuum_threshold     | 3806
   (6 rows)
   
   [local]:5432 #postgres@postgres >
   ```
   Ну. В принципе - логично.
   Рабочая нагрузка от `pgbench` - практически стабильная, конфигурация и условия работы субд - не изменные, от теста к тесту.
   Конфигурация автовакуума - меняется, но в рамках данного теста - стабильная.
   Табличная модель - с особенностями, о которых говорил выше.
   Де-факто, погоду, в смысле затрат и/или импакта от автовакуумирования, делает одна `pgbench_accounts`.
   Т.е. грубо говоря - остальных таблиц: как бы нет.
   Автовакуум выделяет на обработку таблицы - один тред/процесс.
   
   В таких условиях вариативность `autovacuum_max_workers` - не даст вообще ничего.
   Что то может поменять вариантивность в том как часто автовакуум будет обрабатывать `pgbench_accounts`
   Ну, собственно, в отличиях набора параметров автовакуума - это и видно, разница только в этом.
